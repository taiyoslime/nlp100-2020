{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "83\n105\n[<人工>, <知能>, <（>, <じん>, <こうち>, <のう>, <、>, <、>, <AI>, <〈>, <エーアイ>, <〉>, <）>, <と>, <は>, <、>, <「>, <『>, <計算>, <（>, <）>, <』>, <という>, <概念>, <と>, <『>, <コンピュータ>, <（>, <）>, <』>, <という>, <道具>, <を>, <用い>, <て>, <『>, <知能>, <』>, <を>, <研究>, <する>, <計算>, <機>, <科学>, <（>, <）>, <の>, <一>, <分野>, <」>, <を>, <指す>, <語>, <。>, <「>, <言語>, <の>, <理解>, <や>, <推論>, <、>, <問題>, <解決>, <など>, <の>, <知的>, <行動>, <を>, <人間>, <に>, <代わっ>, <て>, <コンピューター>, <に>, <行わ>, <せる>, <技術>, <」>, <、>, <または>, <、>, <「>, <計算>, <機>, <（>, <コンピュータ>, <）>, <による>, <知的>, <な>, <情報処理>, <システム>, <の>, <設計>, <や>, <実現>, <に関する>, <研究>, <分野>, <」>, <と>, <も>, <さ>, <れる>, <。>]\n"
    }
   ],
   "source": [
    "# 40\n",
    "import re\n",
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<{self.surface}>\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.surface\n",
    "\n",
    "docs = \"\"\n",
    "with open('ai.ja.txt.parsed') as f:\n",
    "    docs = f.read()\n",
    "\n",
    "dic = []\n",
    "mor = []\n",
    "for para in docs.split(\"\\n\"):\n",
    "    if para == '' or para[0] == '*':\n",
    "        continue\n",
    "    elif para == \"EOS\":\n",
    "        if mor != []:\n",
    "            dic.append(mor)\n",
    "            mor = []\n",
    "    else:\n",
    "        surface, pos, pos1, pos2, pos3, _, _, base, *_ = re.split('[,\\t]', para)\n",
    "        if surface != '':\n",
    "            mor.append(Morph(surface, base, pos, pos1))\n",
    "\n",
    "print(len(dic))\n",
    "print(len(dic[1]))\n",
    "print(dic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "83\n[<[<『>, <日本>, <大>, <百科全書>, <(>, <ニッポニカ>, <)』>, <の>] [], 1>, <[<解説>, <で>, <、>] [0], 5>, <[<情報>, <工学>, <者>, <・>, <通信>, <工学>, <者>, <の>] [], 3>, <[<佐藤>, <理>, <史>, <は>] [2], 5>, <[<次>, <の>, <よう>, <に>] [], 5>, <[<述べ>, <て>, <いる>, <。>] [1, 3, 4], -1>]\n"
    }
   ],
   "source": [
    "# 41\n",
    "import copy \n",
    "import re\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, morphs, dst, srcs):\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = srcs\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<{self.morphs} {self.srcs}, {self.dst}>\"\n",
    "\n",
    "docs = \"\"\n",
    "with open('ai.ja.txt.parsed') as f:\n",
    "    docs = f.read()\n",
    "\n",
    "dic = []\n",
    "ph = []\n",
    "ph_dest = []\n",
    "mor = []\n",
    "for para in docs.split(\"\\n\"):\n",
    "    if para == '':\n",
    "        continue\n",
    "    elif para[0] == '*':\n",
    "        _, src, dest, *_ = para.split(' ')\n",
    "        dest = dest[:-1] # 末尾のDを削る\n",
    "        ph_dest.append(int(dest))\n",
    "        if mor != []:\n",
    "            ph.append(mor)\n",
    "        mor = []\n",
    "    elif para == \"EOS\":\n",
    "        if mor != []:\n",
    "            ph.append(mor)\n",
    "        if ph != []:\n",
    "            for i in range(len(ph)):\n",
    "                srcs = []\n",
    "                for j in range(len(ph)):\n",
    "                    if ph_dest[j] == i:\n",
    "                        srcs.append(j)\n",
    "                ph[i] = Chunk(ph[i], ph_dest[i], srcs)\n",
    "                \n",
    "            dic.append(ph)\n",
    "        ph = []\n",
    "        ph_dest = []\n",
    "        mor = []\n",
    "    else:\n",
    "        surface, pos, pos1, pos2, pos3, _, _, base, *_ = re.split('[,\\t]', para)\n",
    "        if surface != '':\n",
    "            mor.append(Morph(surface, base, pos, pos1))\n",
    "\n",
    "print(len(dic))\n",
    "print(dic[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2861\n['人工知能 語', 'じんこうちのう 語', 'AI エーアイとは', 'エーアイとは 語', '計算 という', 'という 道具を', '概念と 道具を', 'コンピュータ という', 'という 道具を', '道具を 用いて', '用いて 研究する', '知能を 研究する', '研究する 計算機科学', '計算機科学 の', 'の 一分野を', '一分野を 指す', '指す 語', '語 研究分野とも', '言語の 推論', '理解や 推論', '推論 問題解決などの', '問題解決などの 知的行動を', '知的行動を 代わって', '人間に 代わって', '代わって 行わせる', 'コンピューターに 行わせる', '行わせる 技術または', '技術または 研究分野とも', '計算機 コンピュータによる', 'コンピュータによる 情報処理システムの', '知的な 情報処理システムの', '情報処理システムの 実現に関する', '設計や 実現に関する', '実現に関する 研究分野とも', '研究分野とも される', '日本大百科全書(ニッポニカ)』の 解説で', '解説で 述べている', '情報工学者通信工学者の 佐藤理史は', '佐藤理史は 述べている', '次のように 述べている', '人間の 知的能力を', '知的能力を 実現する', 'コンピュータ上で 実現する', '実現する 技術ソフトウェアコンピュータシステム', '様々な 技術ソフトウェアコンピュータシステム', '技術ソフトウェアコンピュータシステム ある', '応用例は ある', '自然言語処理 機械翻訳かな漢字変換構文解析等', '機械翻訳かな漢字変換構文解析等 専門家の', '専門家の 推論判断を']\n"
    }
   ],
   "source": [
    "phrase_from_to = []\n",
    "for sentence in dic:\n",
    "    for chunk in sentence:\n",
    "        if chunk.dst != -1:\n",
    "            dst_chunk = sentence[chunk.dst]\n",
    "            frm = ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in chunk.morphs ])\n",
    "            to = ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in dst_chunk.morphs])\n",
    "            phrase_from_to.append(f\"{frm} {to}\")\n",
    "\n",
    "print(len(phrase_from_to))\n",
    "print(phrase_from_to[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1325\n['道具を 用いて', '知能を 研究する', '一分野を 指す', '知的行動を 代わって', '人間に 代わって', 'コンピューターに 行わせる', '研究分野とも される', '解説で 述べている', '佐藤理史は 述べている', '次のように 述べている', '知的能力を 実現する', 'コンピュータ上で 実現する', '技術ソフトウェアコンピュータシステム ある', '応用例は ある', '推論判断を 模倣する', '画像データを 解析して', '解析して 検出抽出したりする', 'パターンを 検出抽出したりする', '画像認識等が ある', '1956年に 命名された', 'ダートマス会議で 命名された', 'ジョンマッカーシーにより 命名された', '命名された 使われている', '現在では 使われている', '記号処理を 用いた', '記述を する', '主体と する', '意味あいでも 使われている', '思考ルーチンも 呼ばれる', 'ことも ある', 'カウンセラーを 模倣した', 'プログラム 出されるが', '人工無脳が 出されるが', '引き合いに 出されるが', '計算機に させようという', '役割を させようという', 'エキスパートシステムと 呼ばれる', '実現は 困難視されている', '人間が 持つ', '暗黙に 持つ', '記述が なり', '問題と なり', '利用が 困難視されている', '困難視されている ある', 'アプローチとしては 知られているが', 'アプローチも 知られているが', '差は ある', '記号的明示性に ある', 'その後 集めた', 'サポートベクターマシンが 集めた']\n"
    }
   ],
   "source": [
    "# 43\n",
    "phrase_from_n_to_v = []\n",
    "for sentence in dic:\n",
    "    for chunk in sentence:\n",
    "        dst_chunk = sentence[chunk.dst]\n",
    "        if chunk.dst != -1 and any([morph.pos == \"名詞\" for morph in chunk.morphs]) and any([morph.pos == \"動詞\" for morph in dst_chunk.morphs]):\n",
    "            frm = ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in chunk.morphs ])\n",
    "            to = ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in dst_chunk.morphs])\n",
    "            phrase_from_n_to_v.append(f\"{frm} {to}\")\n",
    "\n",
    "print(len(phrase_from_n_to_v))\n",
    "print(phrase_from_n_to_v[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44\n",
    "import pydot\n",
    "from IPython.display import Image, display_png\n",
    "from graphviz import Digraph\n",
    "\n",
    "edges = []\n",
    "\n",
    "target_sentence = dic[4]\n",
    "for i, chunk in enumerate(target_sentence) :\n",
    "    if chunk.dst != -1:\n",
    "        frm = f'({i}) ' + ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in chunk.morphs ]) \n",
    "        to = f'({chunk.dst}) ' + ''.join([morph.surface if morph.pos != \"記号\" else \"\" for morph in target_sentence[chunk.dst].morphs])\n",
    "        edges.append([frm, to])\n",
    "\n",
    "n = pydot.Node('node')\n",
    "g = pydot.graph_from_edges(edges, directed=True)\n",
    "g.add_node(n)\n",
    "g.write_png('44.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "708\n['用いる を', 'する て を', '指す を', '代わる に を', '行う て に', 'する も', '述べる で に は', 'する で を', 'する を', 'する を']\n"
    }
   ],
   "source": [
    "# 45\n",
    "with open('./45.txt', 'w') as f:\n",
    "    dep_v = []\n",
    "    for sentence in dic:\n",
    "        for chunk in sentence:\n",
    "            if any([morph.pos == \"動詞\" for morph in chunk.morphs]):\n",
    "                verb = \"\"\n",
    "                for morph in chunk.morphs:\n",
    "                    if morph.pos == \"動詞\":\n",
    "                        verb = morph.base\n",
    "                        break\n",
    "                dep_joshi = []\n",
    "                for i in chunk.srcs:\n",
    "                    for morph in reversed(sentence[i].morphs):\n",
    "                        if morph.pos == \"助詞\":\n",
    "                            dep_joshi.append(morph.base)\n",
    "                            break\n",
    "                    \n",
    "                dep_v.append(f\"{verb} {' '.join(sorted(list(set(dep_joshi))))}\")\n",
    "    print(len(dep_v))\n",
    "    print(dep_v[:10])\n",
    "    print(\"\\n\".join(dep_v), file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "51 する を\n  20 する が\n  19 する と\n  17 する に\n  13 する は を\n  11 よる に\n  10 する に を\n   9 する で を\n   8 する と は\n   8 する が に\n"
    }
   ],
   "source": [
    "!cat 45.txt | sort | uniq -c | sort -nr | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8 行う を\n   1 行う まで を\n   1 行う から\n   1 行う に により を\n   1 行う に まで を\n   1 行う は を をめぐって\n   1 行う が て に は\n   1 行う で に を\n   1 行う て に を\n   1 行う が で は\n"
    }
   ],
   "source": [
    "!cat ./45.txt | grep '行う' | sort | uniq -c | sort -nr | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "708\n作り出す は で を ジョン・マッカーシーは 会議で 用語を \n"
    }
   ],
   "source": [
    "# 46\n",
    "dep_v_with_frame = []\n",
    "for sentence in dic:\n",
    "    for chunk in sentence:\n",
    "        if any([morph.pos == \"動詞\" for morph in chunk.morphs]):\n",
    "            verb = \"\"\n",
    "            for morph in chunk.morphs:\n",
    "                if morph.pos == \"動詞\":\n",
    "                    verb = morph.base\n",
    "                    break\n",
    "            dep_joshi = []\n",
    "            dep_frame = []\n",
    "            for i in chunk.srcs:\n",
    "                for j, morph in enumerate(reversed(sentence[i].morphs)):\n",
    "                    if morph.pos == \"助詞\":\n",
    "                        dep_joshi.append(morph.base)\n",
    "                        frame = \"\"\n",
    "                        for m in (sentence[i].morphs[:-j] if j != 0 else sentence[i].morphs):\n",
    "                            frame += m.surface\n",
    "                        dep_frame.append(frame)\n",
    "                        break\n",
    "                \n",
    "            dep_v_with_frame.append(f\"{verb} {' '.join(dep_joshi)} {' '.join(dep_frame)} \")\n",
    "\n",
    "\n",
    "print(len(dep_v_with_frame))\n",
    "\n",
    "# 例に挙げられている「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」の解析結果を出力する\n",
    "[print(v) if any([w == \"作り出す\" in w for w in v.split(\" \")]) else None for v in dep_v_with_frame]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "75\n['行動を代わる に 人間に ', '判断をする   ', '処理を用いる   ', '記述をする と 主体と ', '注目を集める が 「サポートベクターマシン」が ', '経験を行う に を 元に 学習を ', '学習を行う を に 経験を 元に ', '流行を超える   ', '学習を繰り返す   ', '学習をする て は を に を通して なされて ACT-Rでは 推論ルールを 元に 生成規則を通して ', '進化を見せる て は て において 活躍して （敵対的生成ネットワーク）は 加えて 生成技術において ', '生成を行う   ', '開発を行う は エイダ・ラブレスは ', 'テストをする   ', '処理を行う   ', '処理を行う に により に 同年に ティム・バーナーズ＝リーにより Webに ', '意味をする に データに ', '処理を行う て に 付加して コンピュータに ', '研究を進める て 費やして ', '命令をする で 機構で ', '運転をする に 元に ', '特許をする に が 2018年までに 日本が ', '研究をする   ', '運転をする て に 基づいて 柔軟に ', '注目を集める から は ことから ファジィは ', '制御をする   ', '成功を受ける   ', '制御を用いる て も 受けて 他社も ', '制御をする から 少なさから ', '制御をする   ', '進歩を担う   ', '改善を果たす に で が 2012年に 画像処理コンテストで チームが ', 'プログラムを使う   ', '研究を続ける が て ジェフ・ホーキンスが 向けて ', ')をする は 8月には ', '注目を集める に 急速に ', '普及を受ける   ', '学習を組み合わせる   ', '投資を行う に で 全世界的に 民間企業主導で ', '探索を行う で 無報酬で ', '推論をする て 経て ', '研究を始める は とも Googleは マックスプランク研究所とも ', '研究を行う て 始めて ', '開発をする は で 中国では 官民一体で ', '実験をする   ', '開発をする で 日本で ', '投資をする は に 韓国は 2022年までに ', '学習をする   ', 'シミュレーションを行う   ', '反乱を起こす て に対して 於いて 人間に対して ', '弾圧を併せ持つ   ', '監視を行う まで に 歩行者まで 人工知能に ', '手続きを経る を ウイグル族を ', '差別を認める   ', '研究をする   ', '展開を変える   ', '戦争をする   ', '制御をする は AIプログラムは ', '判断を介す から 観点から ', '禁止を求める は が 4月には ヒューマン・ライツ・ウォッチが ', '運用をめぐる   ', '競争を行う は をめぐって 米国・中国・ロシアは 軍事利用をめぐって ', '記録をする   ', '試験を行う   ', '追及を受ける て は とともに と で 暴露されて 公聴会では 「」とともに 拒否すると 整合性で ', '研究をする が Microsoftが ', '解任をする て は 含まれて Google社員らは ', '解散をする は が で Googleは 倫理委員会が 理由で ', '存在を見いだす に ものに ', ')」をする   ', '実現をする   ', '話をする は 哲学者は ', '疎通を行う   ', '勘違いをする   ', '議論を行う まで 「これまで ']\n学習を行う を に 経験を 元に \n"
    }
   ],
   "source": [
    "# 47\n",
    "dep_v_with_frame_s = []\n",
    "for sentence in dic:\n",
    "    for chunk_i, chunk in enumerate(sentence):\n",
    "        if len(chunk.morphs) > 1:\n",
    "            v_frame = \"\"\n",
    "            for i in range(len(chunk.morphs) - 1):\n",
    "                if chunk.morphs[i].pos == \"名詞\" and chunk.morphs[i].pos1 == \"サ変接続\" and chunk.morphs[i+1].pos == \"助詞\" and chunk.morphs[i+1].surface == \"を\":\n",
    "                    v_frame = \"\".join([m.surface for m in chunk.morphs[i:i+2]])\n",
    "                    break\n",
    "            \n",
    "            if v_frame == \"\":\n",
    "                continue\n",
    "                \n",
    "            dest_chunk = sentence[chunk.dst]\n",
    "\n",
    "            if any([morph.pos == \"動詞\" for morph in dest_chunk.morphs]):\n",
    "                verb = \"\"\n",
    "                for morph in dest_chunk.morphs:\n",
    "                    if morph.pos == \"動詞\":\n",
    "                        verb = morph.base\n",
    "                        break\n",
    "                v_frame += verb\n",
    "                dep_joshi = []\n",
    "                dep_frame = []\n",
    "                for i in dest_chunk.srcs:\n",
    "                    if i == chunk_i:\n",
    "                        continue\n",
    "                    for j, morph in enumerate(reversed(sentence[i].morphs)):\n",
    "                        if morph.pos == \"助詞\":\n",
    "                            dep_joshi.append(morph.base)\n",
    "                            frame = \"\"\n",
    "                            for m in (sentence[i].morphs[:-j] if j != 0 else sentence[i].morphs):\n",
    "                                frame += m.surface\n",
    "                            dep_frame.append(frame)\n",
    "                            break\n",
    "                \n",
    "            dep_v_with_frame_s.append(f\"{v_frame} {' '.join(dep_joshi)} {' '.join(dep_frame)} \")\n",
    "\n",
    "print(len(dep_v_with_frame_s))\n",
    "print(dep_v_with_frame_s)\n",
    "\n",
    "# 例に挙げられている「また、自らの経験を元に学習を行う強化学習という手法もある。」の解析結果を出力する\n",
    "[print(v) if any([\"学習を行う\" in w for w in v.split(\" \")]) else None for v in dep_v_with_frame_s]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# 48\n",
    "all_path_n = []\n",
    "for sentence in dic:\n",
    "    for chunk in sentence:\n",
    "        if any([morph.pos == \"名詞\" for morph in chunk.morphs]):\n",
    "            grp = []\n",
    "            chunk_itr = chunk\n",
    "            while chunk_itr.dst != -1 and chunk_itr.morphs[-1].pos1 != \"句点\":\n",
    "                grp.append(\"\".join([m.surface if m.pos != \"記号\" else \"\" for m in chunk_itr.morphs]))\n",
    "                chunk_itr = sentence[chunk_itr.dst]\n",
    "            all_path_n.append(grp)\n",
    "                \n",
    "print(len(all_path_n))\n",
    "#print(all_path_n)\n",
    "[print(path) if \"作り出した\" in path else None for path in all_path_n]\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2410\nジョンマッカーシーは -> 作り出した\nAIに関する -> 最初の -> 会議で -> 作り出した\n最初の -> 会議で -> 作り出した\n会議で -> 作り出した\n人工知能という -> 用語を -> 作り出した\n用語を -> 作り出した\n"
    }
   ],
   "source": [
    "# 48\n",
    "all_path_n = []\n",
    "for sentence in dic:\n",
    "    for chunk in sentence:\n",
    "        if any([morph.pos == \"名詞\" for morph in chunk.morphs]):\n",
    "            grp = []\n",
    "            chunk_itr = chunk\n",
    "            stc_c = True\n",
    "            while chunk_itr.dst != -1 and stc_c:\n",
    "                if chunk_itr.morphs[-1].pos1 == \"句点\":\n",
    "                    stc_c = False\n",
    "                grp.append(\"\".join([m.surface if m.pos != \"記号\" else \"\" for m in chunk_itr.morphs]))\n",
    "                chunk_itr = sentence[chunk_itr.dst]\n",
    "\n",
    "            all_path_n.append(grp)\n",
    "                \n",
    "print(len(all_path_n))\n",
    "# 「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」の結果を出力する\n",
    "[print(\" -> \".join(path)) if \"作り出した\" in path else None for path in all_path_n]\n",
    "None\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1608639617755",
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}